\chapter{Logo Retrieval System}

The difficulties of the problem logo retrieval were highlighted in the introduction, in chapter \ref{c:intro}. Nowadays, deep neural networks are utilized to solve such difficult computer vision problems. In this work, end to end neural network solutions will be used, to retrieve logos from videos. The set of logos to be searched is called the query set. Furthermore the search set is composed of the frames of videos, where the logos should be retrieved from.
\bigbreak
\section{Logo Datasets}\label{s:logodatasets}
The hunger of deep learning methods for training data is well-known. As the publicly available logo datasets are relatively small, a better training result can be achieved, if the datasets are merged. The different logo datasets with the number of brands, images and bounding box RoIs can be seen in table \ref{table:logodatasets}. The total number of brands means the number of different brands altogether.
\bigbreak
There is also a trademark dataset available having a much greater cardinality, called METU Trademark \cite{DBLP:journals/corr/TursunAK17}. However, the images of this dataset contain only the logo of a company, without any context. This dataset turned out to have no use for region based deep learning methods, since this approach needs to learn to distinguish between objects to be learned and the background. The network was trained with the fusion of FlickrLogos-32 and METU trademark dataset. The training setup is described in section \ref{ss:jointlearning}. Then it was tested with the evaluation method of py-faster-R-CNN \cite{Girshick2017} \cite{NIPS2015_5638}, described in chapter \ref{c:experiments}.
\bigbreak
However, this training data is insufficient to train a network from scratch (with randomly initialized weights). Girshick et. al. showed \cite{DBLP:journals/corr/GirshickDDM13}, that initializing the weights of the network from a CNN, which was trained on a not related dataset, and fine-tuning that on the target dataset, can boost on performance significantly. It is because of the hierarchical learning of shapes by the layers of the convolutional neural network. As a result the learning of the first several convolutional layers can even be turned off during fine-tuning. Thus, for all the training in this work, the weights of models are initialized from a network, pretrained on ImageNet classification dataset \cite{imagenet_cvpr09}.
\bigbreak
\begin{table}[ht!]
\centering
\begin{tabular}{|l|l|l|l|}
\hline & \textbf{Number of brands} & \textbf{Number of logo images} & \textbf{Number of RoIs} \\
\hline
\textbf{BelgaLogos \cite{belgalogos09}, \cite{letessier2012scalable}} & 37 & 1321 & 2697 \\
\hline
\textbf{FlickrBelgaLogos \cite{letessier2012scalable}} & 37 & 2697 & 2697 \\
\hline
\textbf{Flickr Logos 27 \cite{619}} & 27 & 810 & 1261 \\
\hline
\textbf{FlickrLogos-32 \cite{RombergICMR2011}} & 32 & $70 \cdot 32 = 2240$ & 3404 \\
\hline
\textbf{Logos-32plus \cite{bianco2017deep}, \cite{bianco2015logo}} & 32 & 7830 & 12300 \\
\hline
\textbf{TopLogo10 \cite{DBLP:journals/corr/SuZG16}} & 10 & $10 \cdot 70 = 700$ & 863 \\
\hline\hline
\textbf{Total} & \textbf{80 (union)} & 15598 & 23222 \\ \hline
\end{tabular}
\caption{Publicly available logo datasets with bounding box annotations}
\label{table:logodatasets}
\end{table}
\bigbreak
For train and evaluation purposes, there were four datasets created, by extracting them from sport videos. These data are needed, to be able to finetune the networks for the specific context. All the logos of these images were annotated despite occlusion and bad sight of them, along with company name. The collected datasets are summarized on table \ref{table:ownlogodatasets}. The utilization of the datasets (training or evaluation) are indicated too. The one, used for testing, is from a different TV broadcasting company then the other three sets.
\bigbreak
\begin{table}[ht!]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline & \textbf{Phase} & \textbf{Number of brands} & \textbf{Number of logo images} & \textbf{Number of RoIs} \\
\hline
\multicolumn{1}{|l|}{\textbf{Football-1}} & \multirow{3}{*}{Train} & \multicolumn{1}{l|}{104} & \multicolumn{1}{l|}{331} & \multicolumn{1}{l|}{3329} \\\cline{1-1}\cline{3-5}
\multicolumn{1}{|l|}{\textbf{Ski}} & & \multicolumn{1}{l|}{27} & \multicolumn{1}{l|}{179} & \multicolumn{1}{l|}{701} \\\cline{1-1}\cline{3-5}
\multicolumn{1}{|l|}{\textbf{Ice hockey}} & & \multicolumn{1}{l|}{19} & \multicolumn{1}{l|}{410} & \multicolumn{1}{l|}{3920} \\\hline
\textbf{Football-2} & Test & 43 & 287 & 2143 \\ \hline
\end{tabular}
\caption{Collected logo datasets from sport videos}
\label{table:ownlogodatasets}
\end{table}
\bigbreak
\section{Logo Detection}\label{s:logodetection}
There are a lot of possibilities to search for objects in an image as explained in section \ref{s:objectdetection}. Keypoint detectors and external proposal systems are translation and rotation invariant, but usually these systems cannot be trained on a specific dataset. Girshick et.al. proposed the Faster R-CNN neural network, detailed in section \ref{s:fasterrcnn}, for end to end learning to detect and classify objects on an image. This network has a bounding box regressor for each trained class, thus it is capable to produce object type specific region proposals.
\bigbreak
In the following sections, different detectors will be introduced.
\bigbreak
\subsection{Region Proposal Network}
During the training of a Faster R-CNN network, a region proposal network will be trained to detect all the kind of objects, which it was trained on. Thus, after training a faster R-CNN with different logos, the trained RPN can be used alone as a logo detector. It has the advantage, that the detector can be extracted from every already trained faster R-CNN network, not like those in case of the following solutions.
\bigbreak
\subsection{Class Agnostic Faster R-CNN}\label{ss:classagnosticdetector}
Faster R-CNN can be trained for two classes: background and logo. For this purpose the classes of every annotation box will be neglected. This solution is expected to yield better performance then the RPN detector. Firstly, because of the fully connected layers preceding the final classifier and the bounding box regression layers. Secondly, it is a cascade of two detectors (RPN and FC), similarly as in \cite{Viola:2004:RRF:966432.966458}, for which it is expected to have a lower false positive rate.
\bigbreak
\section{Logo Comparison}\label{s:logocomparison}
After a logo is detected, a correspondence from the query set should be found. In order to retrieve as much objects from images as possible, the detectors should work with a high recall. Although, for difficult tasks, like open-set logo detection, high recall value induces low precision, thus a lot of false positive possible object locations are produced. These examples should be eliminated by the classifier.
\bigbreak
However, in case of image retrieval the goal is not direct classification, but rather feature extraction of an RoI. Thus, the features of the logos of all the query images and the search set should be collected, which can be solved in several ways.
\bigbreak
\subsection{Faster R-CNN feature extraction}\label{ss:solution1}
The features of both the query and the search set can be extracted by running a faster R-CNN network on them in a standard way, and utilizing the output vectors of the last or the second last layer as features. The advantage of this solution is its speed. This is the fastest solution among the detailed ones. But there are several drawbacks. It has low performance, because of the unknown classes, especially if the net is trained for a small number of classes. This results in a low dimensional feature vector e.g. 32 after training with FlickrLogos-32, by using the class probabilities as feature which yields often the best descriptor. A second issue, which discourages from applying this method for open-set retrieval, occurs during running the network on the query examples.
\bigbreak
The region proposal network outputs more hundred possible object locations (default is 300 in test phase) for every input image. Processing so many query features would immensely increase the computational burden. Thus, it is advantageous to filter the detection list. Although, this cannot be done with the classification scores, since the images contain logos from unknown brands, thus may having an ensemble of brands as descriptor. For this purpose, the score output of the RPN can be used, which is an objectness indicator. This score can be adopted for the detections of the search images too. Therefore, one can take the RoI with the greatest score for query images, and set a low threshold for images of the search set.
\bigbreak
However, there is often the case that the network does not estimate the complete logo with the greatest score, but only a part of that (e.g. the Registered Trade Mark symbol in figure \ref{f:missdet}). This mislocalization destroys the retrieval of that entire class.
\begin{figure}
  \centering
  \includegraphics[width=25mm]{images/mt/missdet.jpg}
  \caption{Misplaced logo detection, with maximum RPN score}
  \label{f:missdet}
\end{figure}
\subsection{Fast(-er) R-CNN feature extraction}\label{ss:solution2}
The drawbacks of the solution in section \ref{ss:solution1} imply, that the RPN should be turned off for the examples of the query set. This means, that the network is applied in fast R-CNN mode on one location, including the complete query image. However, it may yields worse descriptors, because of the loosely fitting bounding box. On the other hand, the logo positions and their features of the search set can be inferred with faster R-CNN, and filtered with a threshold as described in section \ref{ss:solution1}. The retrieved vectors are then normalized and the similarities of them are calculated with cosine distance, which calculates the cosine value of the angle between two vectors. This distance is then used as probability score of the correspondence to a query image. The detections on a particular location, not having the largest score, are eliminated by non-maximum suppression, which searches for other bounding boxes with a minimum IoU of 0.3.
\bigbreak
\subsection{Logo Detector and Fast R-CNN feature extraction}\label{ss:solution3}
The system in the section \ref{ss:solution1} may suffer from the inability of the RPN to localize unknown logos. The solution can be further improved, by using the best logo detector from the section \ref{s:logodetection}.  The output of the detector is then treated as external proposals, and thus the system run in fast R-CNN mode for the images of the search set. This setup is very similar to the one of fast R-CNN, detailed in section \ref{s:fastrcnn}, but utilizing rather neural networks instead of selective search as external region proposal system to collect object locations.

\subsection{Logo Detector and General feature extraction networks}\label{ss:solution4}
Section \ref{s:convnets} details the evolution of convolutional networks by going through the most important ones of today. Donahue et al. proposed \cite{DBLP:journals/corr/DonahueJVHZTD13}, that convolutional networks can produce excellent descriptors of the input image, regardless of the absence of fine-tuning to the specific context of the image. For this purpose, a network is pretrained on very large datasets, after which it can be deployed for a broad set of computer vision problems. But it cannot localize objects on an image. For region proposal purpose, a trained logo detector can be utilized from section \ref{s:logodetection}. This setup of networks is very similar to the R-CNN, detailed in section \ref{s:rcnn}, but omits the use of selective search as external region proposal system. As such,it has the disadvantage of retrieving features of the regions separately from each other, by not sharing the computed feature maps. Thus it needs much more time, to infer a complete image. On the other hand, it is beneficial for the performance, because the complete network is only focused on a specific region. This part of the system can be easily swapped to reach the desired performance / time constraints, since all the kind of networks, explained in section \ref{s:convnets} can be utilized for feature extraction.
\begin{figure}
  \centering
  \includegraphics[width=80mm]{images/mt/det_classif.png}
  \caption{Faster R-CNN and Classifier based logo retrieval system}
  \label{f:missdet}
\end{figure}

\section{Jointly Trained Detector and Classifier}\label{ss:solution5}
Both a class agnostic detector (section \ref{ss:classagnosticdetector}) and a classifier can be built together in a faster R-CNN network. For this purpose, either all fully connected layer or only the two at the end of the network, responsible for classification and bounding box regression should be duplicated. In doing so, one branch will be trained with brand label, the other only with logo object indication. In this network, the weights of the feature extraction layers and the region proposal network can be shared between the two tasks. The easiest way to train such a network is a siamese like faster R-CNN.
\bigbreak
Siamese networks \cite{Hadsell06dimensionalityreduction} are basically used for calculating similarity scores between inputs. If it is combined with an appropriate loss function e.g. contrastive loss \cite{Hadsell06dimensionalityreduction} or max margin loss \cite{Simonyan13}\cite{ies_2016_herrmann_low_quality}, the network can be trained with an image pair and a label indicating whether the objects on the images are from the same category or not. The network than learns to project objects from the same category with a low-, otherwise with a large distance to each other, according to a specified metric. This is achieved by sharing the weights of the feature extraction layers.
\bigbreak
For faster R-CNN, the parameters for region proposal network can also be shared. This setup has the advantage, that training of one task can also improve the performance of the other task, which is not currently trained. In particular for logo retrieval, the network can benefit from a bounding box annotated logo dataset, without specific brand indication. To annotate such a dataset it is much less human resource needed. A quantitative evaluation can be found in section \ref{s:explogodetection}. A schematic illustration of the training and test setup can be seen in figure \ref{f:jointlearning}.
\bigbreak
\begin{figure}
  \centering
\begin{tabular}{cccc}
  \includegraphics[height=60mm]{images/mt/siamtrain.png} &   \includegraphics[height=60mm]{images/mt/siamtest.png}
\end{tabular}
\caption{Network setups in train and test phases for learning detection and classification jointly}
\label{f:jointlearning}
\end{figure}
\bigbreak

